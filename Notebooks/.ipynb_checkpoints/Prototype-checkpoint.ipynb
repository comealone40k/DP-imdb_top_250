{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1ee2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, html\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s\\t%(asctime)s\\t%(funcName)s\\t%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6dfbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_page_link(p_start_url: str, p_log_level:str = 'INFO') -> list:\n",
    "    \n",
    "    logger = logging.getLogger(__name__.ljust(30, ' '))\n",
    "    logger.setLevel(p_log_level)\n",
    "    \n",
    "    all_urls = []\n",
    "    url = p_start_url\n",
    "        \n",
    "    logger.info(f'Start URL: {url}')\n",
    "        \n",
    "    while(url != None):            #Loop around all the required webpages and terminates when last page arive!\n",
    "        all_urls.append(url)\n",
    "        soup = BeautifulSoup(requests.get(url).text,\"html.parser\")\n",
    "        next_links = soup.find_all(class_='flat-button lister-page-next next-page')    #Extracts the next page link.\n",
    "        if (len(next_links) == 0):         # If their is no next page, it returns 0.\n",
    "            url = None\n",
    "        \n",
    "            logger.debug('No more pages')\n",
    "                \n",
    "        else:\n",
    "            next_page = \"https://www.imdb.com\" + next_links[0].get('href')\n",
    "                \n",
    "            url = next_page\n",
    "        \n",
    "            logger.debug(f'Next page: {url}')\n",
    "            \n",
    "    logger.info(f'Finished, Page links are gathered for URL: {url}')\n",
    "    logger.debug(f'URLs:\\n{all_urls}')\n",
    "                \n",
    "    return all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839fdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_imdb_data(p_content: str, p_log_level:str = 'INFO') -> list:\n",
    "    \n",
    "    logger = logging.getLogger(__name__.ljust(30, ' '))\n",
    "    logger.setLevel(p_log_level)\n",
    "        \n",
    "    logger.info('Started')\n",
    "        \n",
    "    logger.debug(f'Current content:\\n{p_content}')\n",
    "    \n",
    "    soup = BeautifulSoup(p_content, 'html.parser')\n",
    "\n",
    "    soup_data = soup.find(\"script\", type=\"application/ld+json\").text\n",
    "\n",
    "    imdb_data = json.loads(soup_data)\n",
    "    \n",
    "    l_movie_name = html.unescape(imdb_data['name'])\n",
    "        \n",
    "    logger.debug(f'Data extracted from content:\\n{imdb_data}')\n",
    "\n",
    "    soup_oscars = soup.findAll(\"a\", attrs={\"class\":\"ipc-metadata-list-item__label ipc-metadata-list-item__label--link\"})\n",
    "        \n",
    "    num_of_oscars = 0\n",
    "    for i in soup_oscars:\n",
    "        if re.search('Won(.+?)Oscars',i.text):\n",
    "            num_of_oscars = int(re.findall(r'\\d+',i.text)[0])\n",
    "\n",
    "            logger.debug(f'Found Oscars: {num_of_oscars} in: {i.text}')\n",
    "            \n",
    "    try:\n",
    "        release_date = imdb_data['datePublished']\n",
    "    except KeyError as ke:\n",
    "        logger.warning(f'Publish date was not found for: {l_movie_name}')\n",
    "        release_date = 'N/A'\n",
    "    \n",
    "    l_return =  [l_movie_name,\n",
    "                 release_date,\n",
    "                 imdb_data['aggregateRating']['ratingValue'],\n",
    "                 imdb_data['aggregateRating']['ratingCount'],\n",
    "                 num_of_oscars]\n",
    "        \n",
    "    logger.info(f'Finished, Extracted data: {l_return}')\n",
    "    \n",
    "    return l_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967047fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_imdb_top_250_data(p_log_level:str = 'INFO') -> pd.DataFrame:\n",
    "    \n",
    "    logger = logging.getLogger(__name__.ljust(30, ' '))\n",
    "    logger.setLevel(p_log_level)\n",
    "        \n",
    "    logger.info('Started')\n",
    "    \n",
    "    l_top_250_url = \"https://www.imdb.com/list/ls068082370/\"\n",
    "        \n",
    "    logger.debug(f'Starting on URL: {l_top_250_url}')\n",
    "        \n",
    "    t = tqdm(all_page_link(p_start_url=l_top_250_url, p_log_level=p_log_level))\n",
    "    \n",
    "    links_set = set()\n",
    "    for i in t:\n",
    "        soup = BeautifulSoup(requests.get(i).text,\"html.parser\")\n",
    "        links = [a['href'] for a in soup.select('a[href]')]\n",
    "        current_link_set = set(list(filter(lambda link: 'title/tt' in link, links)))\n",
    "        \n",
    "        logger.debug(f'Adding links:\\n{current_link_set}')\n",
    "        \n",
    "        links_set = links_set.union(current_link_set)\n",
    "        \n",
    "    logger.debug(f'Current set of links:\\n{links}')\n",
    "        \n",
    "    imdb_top_250_data = []\n",
    "    for link in links_set:\n",
    "        l_current_link = f'https://www.imdb.com{link}'\n",
    "        \n",
    "        logger.debug(f'Extracting data from URL:{l_current_link}')\n",
    "            \n",
    "        l_content = requests.get(l_current_link).content\n",
    "        imdb_top_250_data.append(extract_imdb_data(p_content=l_content, p_log_level=p_log_level))\n",
    "        \n",
    "    index = [\"name\", \"release_date\", \"rating\", \"votes\", \"oscars\"]\n",
    "\n",
    "    df = pd.DataFrame(imdb_top_250_data,columns=index)\n",
    "        \n",
    "    logger.info(f'Finished, Result dataframe:\\n{df}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03aae628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscars_adjustment(p_num_of_oscars: int) -> float:\n",
    "    if p_num_of_oscars == 0:\n",
    "        return 0\n",
    "    elif p_num_of_oscars > 0 and p_num_of_oscars < 3:\n",
    "        return 0.3\n",
    "    elif p_num_of_oscars > 2 and p_num_of_oscars < 6:\n",
    "        return 0.5\n",
    "    elif p_num_of_oscars > 5 and p_num_of_oscars < 11:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b8cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_imdb_data_to_csv(p_df:pd.DataFrame, \n",
    "                           p_file:str, \n",
    "                           p_sep:str = ';', \n",
    "                           p_overwrite:bool = False, \n",
    "                           p_log_level:str = 'INFO'):\n",
    "    \n",
    "    logger = logging.getLogger(__name__.ljust(30, ' '))\n",
    "    logger.setLevel(p_log_level)\n",
    "        \n",
    "    logger.info(f'Started writing file: {p_file}')\n",
    "    \n",
    "    p_df.to_csv(path_or_buf=p_file, sep=p_sep, index=True, header=True, index_label='rank')\n",
    "        \n",
    "    logger.info(f'Finished writing file: {p_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbae388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2022-10-23 11:39:01,616\textract_imdb_top_250_data\tStarted\n",
      "INFO\t2022-10-23 11:39:01,622\tall_page_link\tStart URL: https://www.imdb.com/list/ls068082370/\n",
      "INFO\t2022-10-23 11:39:17,235\tall_page_link\tFinished, Page links are gathered for URL: None\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.08s/it]\n",
      "INFO\t2022-10-23 11:39:30,890\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:31,445\textract_imdb_data\tFinished, Extracted data: ['M - Eine Stadt sucht einen Mörder', '1931-08-31', 8.3, 157942, 0]\n",
      "INFO\t2022-10-23 11:39:32,421\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:33,037\textract_imdb_data\tFinished, Extracted data: ['The Prestige', '2007-01-04', 8.5, 1322013, 0]\n",
      "INFO\t2022-10-23 11:39:34,386\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:34,507\textract_imdb_data\tFinished, Extracted data: ['Modern Times', '1936-10-07', 8.5, 241850, 0]\n",
      "INFO\t2022-10-23 11:39:36,018\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:36,155\textract_imdb_data\tFinished, Extracted data: ['Chinatown', '1979-09-27', 8.2, 326025, 0]\n",
      "INFO\t2022-10-23 11:39:37,578\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:38,063\textract_imdb_data\tFinished, Extracted data: ['El laberinto del fauno', '2007-03-08', 8.2, 666296, 3]\n",
      "INFO\t2022-10-23 11:39:39,793\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:40,290\textract_imdb_data\tFinished, Extracted data: ['Casino', '1996-03-07', 8.2, 517317, 0]\n",
      "INFO\t2022-10-23 11:39:41,793\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:41,922\textract_imdb_data\tFinished, Extracted data: [\"One Flew Over the Cuckoo's Nest\", '1977-05-19', 8.7, 1001429, 5]\n",
      "INFO\t2022-10-23 11:39:43,345\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:43,473\textract_imdb_data\tFinished, Extracted data: ['Dangal', '2016-12-21', 8.3, 190363, 0]\n",
      "INFO\t2022-10-23 11:39:44,776\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:44,906\textract_imdb_data\tFinished, Extracted data: ['The Apartment', '1961-07-27', 8.3, 181410, 5]\n",
      "INFO\t2022-10-23 11:39:46,468\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:46,612\textract_imdb_data\tFinished, Extracted data: ['L.A. Confidential', '1998-01-29', 8.2, 581313, 2]\n",
      "INFO\t2022-10-23 11:39:48,134\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:48,351\textract_imdb_data\tFinished, Extracted data: ['Monsters, Inc.', '2002-02-14', 8.1, 903059, 0]\n",
      "INFO\t2022-10-23 11:39:49,841\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:50,309\textract_imdb_data\tFinished, Extracted data: ['The Elephant Man', '1985-12-19', 8.2, 240957, 0]\n",
      "INFO\t2022-10-23 11:39:51,794\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:51,920\textract_imdb_data\tFinished, Extracted data: ['Once Upon a Time in America', '1989-03-30', 8.3, 350812, 0]\n",
      "INFO\t2022-10-23 11:39:53,382\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:53,507\textract_imdb_data\tFinished, Extracted data: ['Gangs of Wasseypur', '2012-06-22', 8.2, 96211, 0]\n",
      "INFO\t2022-10-23 11:39:55,103\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:55,218\textract_imdb_data\tFinished, Extracted data: ['Salinui chueok', '2003-05-02', 8.1, 182374, 0]\n",
      "INFO\t2022-10-23 11:39:56,871\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:57,646\textract_imdb_data\tFinished, Extracted data: ['A Clockwork Orange', '1972-01-13', 8.3, 825182, 0]\n",
      "INFO\t2022-10-23 11:39:59,236\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:39:59,500\textract_imdb_data\tFinished, Extracted data: ['Lawrence of Arabia', '1962-12-11', 8.3, 293185, 7]\n",
      "INFO\t2022-10-23 11:40:00,769\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:00,903\textract_imdb_data\tFinished, Extracted data: ['The Jungle Book', '2016-04-21', 7.4, 277467, 0]\n",
      "INFO\t2022-10-23 11:40:02,304\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:02,437\textract_imdb_data\tFinished, Extracted data: ['Fargo', '1997-02-27', 8.1, 675210, 2]\n",
      "INFO\t2022-10-23 11:40:03,840\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:03,962\textract_imdb_data\tFinished, Extracted data: ['Witness for the Prosecution', '1962-01-22', 8.4, 125321, 0]\n",
      "INFO\t2022-10-23 11:40:05,336\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:05,532\textract_imdb_data\tFinished, Extracted data: ['Sholay', '1975-08-15', 8.1, 55983, 0]\n",
      "INFO\t2022-10-23 11:40:07,259\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:07,535\textract_imdb_data\tFinished, Extracted data: ['How to Train Your Dragon', '2010-03-25', 8.1, 735825, 0]\n",
      "INFO\t2022-10-23 11:40:08,495\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:08,742\textract_imdb_data\tFinished, Extracted data: ['Mary and Max.', '2010-09-30', 8.1, 177345, 0]\n",
      "INFO\t2022-10-23 11:40:10,264\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:10,397\textract_imdb_data\tFinished, Extracted data: ['Monty Python and the Holy Grail', '1977-08-11', 8.2, 540063, 0]\n",
      "INFO\t2022-10-23 11:40:11,427\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:11,567\textract_imdb_data\tFinished, Extracted data: ['Aliens', '1988-04-21', 8.4, 713649, 2]\n",
      "INFO\t2022-10-23 11:40:14,137\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:14,292\textract_imdb_data\tFinished, Extracted data: ['Star Wars: Episode VII - The Force Awakens', '2015-12-18', 7.8, 926120, 0]\n",
      "INFO\t2022-10-23 11:40:15,550\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:15,670\textract_imdb_data\tFinished, Extracted data: ['The Silence of the Lambs', '1992-03-27', 8.6, 1418736, 5]\n",
      "INFO\t2022-10-23 11:40:16,724\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:17,644\textract_imdb_data\tFinished, Extracted data: ['Jagten', '2013-02-21', 8.3, 328165, 0]\n",
      "INFO\t2022-10-23 11:40:19,453\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:19,588\textract_imdb_data\tFinished, Extracted data: ['The Dark Knight Rises', '2012-07-26', 8.4, 1690521, 0]\n",
      "INFO\t2022-10-23 11:40:20,752\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:20,882\textract_imdb_data\tFinished, Extracted data: ['Spotlight', '2016-02-18', 8.1, 468045, 2]\n",
      "INFO\t2022-10-23 11:40:22,607\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:22,741\textract_imdb_data\tFinished, Extracted data: ['Inside Out', '2015-06-25', 8.2, 707601, 0]\n",
      "INFO\t2022-10-23 11:40:24,049\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:24,186\textract_imdb_data\tFinished, Extracted data: ['The Wizard of Oz', '1940-03-21', 8.1, 398426, 2]\n",
      "INFO\t2022-10-23 11:40:25,166\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:25,429\textract_imdb_data\tFinished, Extracted data: ['Raiders of the Lost Ark', '1985-10-24', 8.4, 960053, 4]\n",
      "INFO\t2022-10-23 11:40:26,758\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:27,376\textract_imdb_data\tFinished, Extracted data: ['Citizen Kane', '1947-07-28', 8.3, 440946, 0]\n",
      "INFO\t2022-10-23 11:40:28,607\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:28,745\textract_imdb_data\tFinished, Extracted data: ['Forrest Gump', '1994-12-08', 8.8, 2054982, 6]\n",
      "INFO\t2022-10-23 11:40:29,654\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:29,768\textract_imdb_data\tFinished, Extracted data: ['Andrey Rublyov', '1973-04-05', 8.1, 53816, 0]\n",
      "INFO\t2022-10-23 11:40:31,092\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:31,213\textract_imdb_data\tFinished, Extracted data: ['Trainspotting', '1996-10-03', 8.1, 684565, 0]\n",
      "INFO\t2022-10-23 11:40:32,283\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:32,394\textract_imdb_data\tFinished, Extracted data: ['The Big Lebowski', '1998-09-24', 8.1, 804402, 0]\n",
      "INFO\t2022-10-23 11:40:34,022\textract_imdb_data\tStarted\n",
      "INFO\t2022-10-23 11:40:34,288\textract_imdb_data\tFinished, Extracted data: ['Eternal Sunshine of the Spotless Mind', '2004-08-19', 8.3, 1000508, 0]\n"
     ]
    }
   ],
   "source": [
    "df = extract_imdb_top_250_data(p_log_level='INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3447702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71392d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('rating', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_votes = df.sort_values('rating', ascending=False).head(20).max(axis = 0)['votes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94709e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['adjusted_rating1'] = df['rating'] + ((max_votes - df['votes']) // 100000  * -0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f384bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['adjusted_rating2'] =  [oscars_adjustment(x) for x in df['oscars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ba315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['adjusted_rating'] = df['adjusted_rating1'] + df['adjusted_rating2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"adjusted_rating1\", axis='columns')\n",
    "df = df.drop(\"adjusted_rating2\", axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values('adjusted_rating', ascending=False).head(20).reindex().reset_index(drop=True)\n",
    "sorted_df.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a94ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acbaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_imdb_data_to_csv(p_df=sorted_df, p_file=f'imdb_top_250_adjusted_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
